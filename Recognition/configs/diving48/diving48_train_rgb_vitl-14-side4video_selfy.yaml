resume:
pretrain: "exp/s4v_selfy_vitl14_16x224_k400_run3/model_best.pt"
seed: 1024
data:
    dataset: diving48
    modality: RGB
    num_segments: 32
    seg_length: 1
    batch_size: 12
    test_batch_size: 4
    workers: 4
    num_classes: 48
    image_tmpl: "img_{:05d}.jpg"
    train_root: "/home/mjkim/datasets/diving48"
    train_list: "lists/diving48/train_rgb_320px_60fps_v2.txt"
    val_root: "/home/mjkim/datasets/diving48"
    val_list: "lists/diving48/val_rgb_320px_60fps_v2.txt" #
    label_list: "lists/diving48_labels.csv"
    input_size: 224
    random_shift: True
    num_sample: 1
    rand_aug: False
    rand_erase: False
network:
    arch: ViT-L/14  #ViT-B/32 ViT-B/16
    init: True
    tm: False # localuni t1d atm False
    dropout: 0.0
    emb_dropout: 0.0 
    type: clip_k400
    sim_header: None  # Transf   None  
    joint_st: False
    drop_fc: 0     
    n_emb: 448
    side_dim: 448
    corr_layer_index: [7]
    corr_dim: 256
    corr_func: "cosine" # 'cosine', 'dotproduct_softmax'
    corr_window: [5, 9, 9]
    corr_ext_chnls: [64]
    corr_int_chnls: [64, 64, 128]
    corr_num_encoders: 2
    fix_clip: False 
    my_fix_clip: True
    sync_bn: False
    num_checkpoints: 24
solver:
    type: cosine
    epochs: 30
    start_epoch: 0
    epoch_offset: 0
    optim: adamw
    lr: 2.e-4
    warmup_lr: 2.e-7
    lr_warmup_step: 4
    final_factor: 0.01
    weight_decay: 0.15
    loss_type: CE
    evaluate: False
    betas: [0.9, 0.999]
    clip_ratio: 1
    grad_accumulation_steps: 1  
    smoothing: 0.1
    layer_decay: 1.0 # 0.7
logging:
    print_freq: 10
    eval_freq: 2
    skip_epoch: []
    acc_per_class: True
    correct_per_sample: True
wandb:
    use_wandb: True
    entity: mandos
    key: "5663c183a53a252ec9b39f4816e68bfe70f72107"
    project_name: "corr_adapter_diving48"
    exp_name: "default"
    group_name: None